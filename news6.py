import streamlit as st
import pandas as pd
import requests
from urllib.parse import quote, urlparse, parse_qs
from bs4 import BeautifulSoup
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import plotly.express as px
from datetime import datetime
from io import BytesIO
from collections import Counter
import re
import feedparser

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ğŸ§  AI ë‰´ìŠ¤ ìš”ì•½ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸ“° AI/ë¡œë´‡ ë‰´ìŠ¤ ìš”ì•½ ëŒ€ì‹œë³´ë“œ")

# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.header("ğŸ” ë‰´ìŠ¤ ìˆ˜ì§‘ ì¡°ê±´")
KEYWORDS = ["AI", "ë¡œë´‡", "ë¡œë´‡ê°ì •", "ë¡œë´‡ì„±ê²©", "IT", "ì‚°ì—…ë°ì´í„°", "ë°ì´í„°ì‹œìŠ¤í…œ"]
selected_keywords = st.sidebar.multiselect("ğŸ’¡ í‚¤ì›Œë“œ ì„ íƒ", KEYWORDS, default=KEYWORDS[:3])
extra_kw = st.sidebar.text_input("â• ì¶”ê°€ í‚¤ì›Œë“œ (ì‰¼í‘œ êµ¬ë¶„)")
if extra_kw:
    selected_keywords += [kw.strip() for kw in extra_kw.split(",") if kw.strip()]
lang_option = st.sidebar.radio("ğŸŒ ë‰´ìŠ¤ ì–¸ì–´", ["í•œêµ­ì–´", "ì˜ì–´"])
max_items = st.sidebar.slider("ğŸ“° í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ìˆ˜", 1, 10, 3)
start_date = st.sidebar.date_input("ğŸ“… ì‹œì‘ì¼", None)
end_date = st.sidebar.date_input("ğŸ“… ì¢…ë£Œì¼", None)

# ì´ëª¨ì§€ ì„¤ì •
SENTI_EMOJI = {"ê¸ì •": "ğŸŸ¢", "ë¶€ì •": "ğŸ”´", "ì¤‘ë¦½": "ğŸŸ¡"}
TONE_EMOJI = {"ì •ë³´ì„±": "â„¹ï¸", "ê°ì •ì ": "ğŸ’¬", "ë¶„ì„ì ": "ğŸ§"}

def clean_text(html):
    """HTML íƒœê·¸ ì œê±°"""
    return BeautifulSoup(html, "html.parser").get_text(separator=" ").strip()

def simple_summarize(text, num_sent=2):
    """ê°„ë‹¨í•œ ìš”ì•½ (AI ëª¨ë¸ ì—†ì´)"""
    if not text or len(text.strip()) < 30:
        return "ìš”ì•½ ë¶ˆê°€ (ë³¸ë¬¸ ë¶€ì¡±)"
    
    # ë¬¸ì¥ ë¶„ë¦¬
    sentences = [s.strip() for s in text.replace("!", ".").split(". ") if len(s.strip()) > 15]
    
    if len(sentences) <= num_sent:
        return text[:300] + "..." if len(text) > 300 else text
    
    # ì²« ë²ˆì§¸ì™€ ì¤‘ê°„ ë¬¸ì¥ ì„ íƒ
    selected = [sentences[0]]
    if len(sentences) > 2:
        selected.append(sentences[len(sentences)//2])
    
    return ". ".join(selected)

def extract_keywords(text, n=5):
    """í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë¹ˆë„ ê¸°ë°˜)"""
    KOREAN_STOPWORDS = {'ìˆë‹¤', 'í•˜ë‹¤', 'ìˆ˜', 'ë“±', 'ë°', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ì´ë²ˆ',
                        'ê´€í•œ', 'í•˜ì—¬', 'ëŒ€í•œ', 'ê´€ë ¨', 'í•œ', 'ë”', 'ìˆìœ¼ë©°', 'ë”°ë¼', 'ë“±ì˜'}
    
    words = re.findall(r"[ê°€-í£]{2,}", text)
    words = [w for w in words if w not in KOREAN_STOPWORDS and len(w) > 1]
    freq = Counter(words)
    return ", ".join([w for w, _ in freq.most_common(n)]) if freq else "í‚¤ì›Œë“œ ì—†ìŒ"

def simple_sentiment(text):
    """ê°„ë‹¨í•œ ê°ì„± ë¶„ì„ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
    positive_words = ['ì¢‹ë‹¤', 'í›Œë¥­', 'ì„±ê³µ', 'ë°œì „', 'í˜ì‹ ', 'ê°œì„ ', 'ì¦ê°€', 'ìƒìŠ¹', 'ê¸ì •']
    negative_words = ['ë‚˜ì˜ë‹¤', 'ë¬¸ì œ', 'ì‹¤íŒ¨', 'ìš°ë ¤', 'ë…¼ë€', 'ê°ì†Œ', 'í•˜ë½', 'ë¶€ì •', 'ìœ„í—˜']
    
    pos_count = sum(1 for word in positive_words if word in text)
    neg_count = sum(1 for word in negative_words if word in text)
    
    if pos_count > neg_count:
        return "ê¸ì •"
    elif neg_count > pos_count:
        return "ë¶€ì •"
    else:
        return "ì¤‘ë¦½"

def analyze_tone(text):
    """ì½˜í…ì¸  í†¤ ë¶„ì„"""
    if any(word in text for word in ["ë¶„ì„", "ì—°êµ¬", "ì¡°ì‚¬", "ë°ì´í„°", "í†µê³„"]):
        return "ë¶„ì„ì "
    elif any(word in text for word in ["ë†€ë¼", "ì¶©ê²©", "ê°ë™", "ê¸°ì˜", "ìŠ¬í”„"]):
        return "ê°ì •ì "
    else:
        return "ì •ë³´ì„±"

def generate_tags(text):
    """íƒœê·¸ ìƒì„±"""
    tags = []
    if "ê¸°ìˆ " in text or "AI" in text:
        tags.append("#ê¸°ìˆ ë™í–¥")
    if "ì‹œì¥" in text or "ìˆ˜ìš”" in text:
        tags.append("#ì‹œì¥ë¶„ì„")
    if "ë…¼ë€" in text or "ë¬¸ì œ" in text:
        tags.append("#ì´ìŠˆ")
    return " ".join(tags) if tags else "#ì¼ë°˜"

def generate_opinion(sentiment, tone):
    """í•œì¤„í‰ ìƒì„±"""
    senti_txt = {
        "ê¸ì •": "ğŸŸ¢ ê¸ì •ì ì¸ ê´€ì ",
        "ë¶€ì •": "ğŸ”´ ë¹„íŒì ì¸ ê´€ì ", 
        "ì¤‘ë¦½": "ğŸŸ¡ ì¤‘ë¦½ì ì¸ ê´€ì "
    }.get(sentiment, "ğŸŸ¡ ì¤‘ë¦½ì ì¸ ê´€ì ")
    
    tone_txt = {
        "ì •ë³´ì„±": "â„¹ï¸ ì •ë³´ ì „ë‹¬",
        "ê°ì •ì ": "ğŸ’¬ ê°ì • í‘œí˜„",
        "ë¶„ì„ì ": "ğŸ§ ë¶„ì„ì  ì ‘ê·¼"
    }.get(tone, "â„¹ï¸ ì •ë³´ ì „ë‹¬")
    
    return f"{senti_txt} + {tone_txt}ì˜ ë‰´ìŠ¤ì…ë‹ˆë‹¤."

@st.cache_data(show_spinner=True, ttl=3600)
def fetch_news(keyword, lang="ko", max_items=3):
    """ë‰´ìŠ¤ ìˆ˜ì§‘"""
    try:
        q = quote(keyword)
        lang_code = "ko" if lang == "í•œêµ­ì–´" or lang == "ko" else "en"
        rss_url = f"https://news.google.com/rss/search?q={q}&hl={lang_code}&gl=KR&ceid=KR:{lang_code}"
        
        response = requests.get(rss_url, timeout=10)
        if response.status_code != 200:
            return pd.DataFrame()
        
        feed = feedparser.parse(response.text)
        articles = []
        
        for entry in feed.entries[:max_items]:
            try:
                title = entry.title
                # Google News ë¦¬ë‹¤ì´ë ‰íŠ¸ ë§í¬ ì²˜ë¦¬
                original_link = entry.link
                
                # Google News ë§í¬ì—ì„œ ì‹¤ì œ URL ì¶”ì¶œ ì‹œë„
                if 'news.google.com' in original_link and 'url=' in original_link:
                    try:
                        # URL íŒŒë¼ë¯¸í„°ì—ì„œ ì‹¤ì œ ë§í¬ ì¶”ì¶œ
                        parsed = urlparse(original_link)
                        query_params = parse_qs(parsed.query)
                        if 'url' in query_params:
                            link = query_params['url'][0]
                        else:
                            link = original_link
                    except:
                        link = original_link
                else:
                    link = original_link
                
                date = entry.get("published", datetime.now().strftime("%Y-%m-%d"))
                preview = clean_text(entry.summary if hasattr(entry, "summary") else "")
                
                # ë³¸ë¬¸ ëŒ€ì‹  ìš”ì•½ë¬¸ ì‚¬ìš© (ì†ë„ í–¥ìƒ)
                fulltext = preview if preview else title
                
                summary = simple_summarize(fulltext)
                keywords = extract_keywords(fulltext)
                sentiment = simple_sentiment(fulltext)
                tone = analyze_tone(fulltext)
                tags = generate_tags(fulltext)
                opinion = generate_opinion(sentiment, tone)
                
                articles.append({
                    "í‚¤ì›Œë“œ": keyword,
                    "ì œëª©": title,
                    "ë§í¬": link,
                    "ë‚ ì§œ": date,
                    "ë³¸ë¬¸": fulltext,
                    "ìš”ì•½": summary,
                    "í‚¤ì›Œë“œì¶”ì¶œ": keywords,
                    "ê°ì„±": sentiment,
                    "ì½˜í…ì¸ í†¤": tone,
                    "íƒœê·¸": tags,
                    "í•œì¤„í‰": opinion
                })
            except Exception as e:
                st.warning(f"ë‰´ìŠ¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
                
        return pd.DataFrame(articles)
    except Exception as e:
        st.error(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return pd.DataFrame()

# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if st.button("ğŸ” ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘", type="primary"):
    if not selected_keywords:
        st.warning("í‚¤ì›Œë“œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!")
    else:
        lang_code = "ko" if lang_option == "í•œêµ­ì–´" else "en"
        
        with st.spinner("ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            df_list = []
            progress_bar = st.progress(0)
            
            for i, keyword in enumerate(selected_keywords):
                df = fetch_news(keyword, lang=lang_code, max_items=max_items)
                if not df.empty:
                    df_list.append(df)
                progress_bar.progress((i + 1) / len(selected_keywords))
            
            progress_bar.empty()
            
            if df_list:
                news_df = pd.concat(df_list, ignore_index=True).drop_duplicates(subset=["ë§í¬"])
                st.session_state['news_df'] = news_df
                st.success(f"ì´ {len(news_df)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
            else:
                st.warning("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.session_state['news_df'] = pd.DataFrame()

# ì„¸ì…˜ì—ì„œ ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
news_df = st.session_state.get('news_df', pd.DataFrame())

# ë‚ ì§œ í•„í„°ë§
if not news_df.empty:
    news_df["ë‚ ì§œ"] = pd.to_datetime(news_df["ë‚ ì§œ"], errors="coerce")
    if start_date:
        news_df = news_df[news_df["ë‚ ì§œ"] >= pd.to_datetime(start_date)]
    if end_date:
        news_df = news_df[news_df["ë‚ ì§œ"] <= pd.to_datetime(end_date)]

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ğŸ“° ë‰´ìŠ¤ ëª©ë¡", "ğŸ“Š í†µê³„Â·ì›Œë“œí´ë¼ìš°ë“œ", "ğŸ“ ë¶ë§ˆí¬/PDF"])

with tab1:
    st.subheader("ğŸ“° ìµœì‹  ë‰´ìŠ¤ ëª©ë¡")
    if not news_df.empty:
        if "bookmarks" not in st.session_state:
            st.session_state["bookmarks"] = []
            
        for i, row in news_df.iterrows():
            senti_emo = SENTI_EMOJI.get(row["ê°ì„±"], "ğŸŸ¡")
            tone_emo = TONE_EMOJI.get(row["ì½˜í…ì¸ í†¤"], "â„¹ï¸")
            
            # ì œëª©ê³¼ ë§í¬ë¥¼ ì•ˆì „í•˜ê²Œ í‘œì‹œ
            st.markdown(f"### {senti_emo}{tone_emo} {row['ì œëª©']}")
            st.markdown(f"ğŸ”— **ë§í¬:** {row['ë§í¬']}")
            st.caption(f"ğŸ“… {row['ë‚ ì§œ'].date()} | {senti_emo} ê°ì„±: `{row['ê°ì„±']}` | {tone_emo} í†¤: `{row['ì½˜í…ì¸ í†¤']}` | {row['íƒœê·¸']}")
            st.markdown(f"ğŸ§¾ **ìš”ì•½:** {row['ìš”ì•½']}")
            st.markdown(f"ğŸ’¡ **í•œì¤„í‰:** {row['í•œì¤„í‰']}")
            st.markdown(f"ğŸ·ï¸ `{row['í‚¤ì›Œë“œì¶”ì¶œ']}`")
            
            if st.button("â­ ë¶ë§ˆí¬", key=f"bookmark_{i}"):
                if row["ë§í¬"] not in st.session_state["bookmarks"]:
                    st.session_state["bookmarks"].append(row["ë§í¬"])
                    st.success("ë¶ë§ˆí¬ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.divider()
    else:
        st.info("ğŸ” ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”!")

with tab2:
    st.subheader("ğŸ“Š ë‰´ìŠ¤ í†µê³„ ë° ì›Œë“œí´ë¼ìš°ë“œ")
    if not news_df.empty:
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown("#### ğŸ”¢ í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ìˆ˜")
            keyword_counts = news_df["í‚¤ì›Œë“œ"].value_counts()
            st.bar_chart(keyword_counts)
            
            st.markdown("#### ğŸ˜¶ ê°ì„± ë¶„í¬")
            sentiment_counts = news_df["ê°ì„±"].value_counts()
            st.bar_chart(sentiment_counts)
            
            st.markdown("#### ğŸ§ ì½˜í…ì¸  í†¤ ë¶„í¬")
            fig = px.histogram(news_df, x="í‚¤ì›Œë“œ", color="ì½˜í…ì¸ í†¤", barmode="group")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.markdown("#### â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ")
            all_keywords = ", ".join(news_df["í‚¤ì›Œë“œì¶”ì¶œ"].dropna())
            
            if all_keywords:
                try:
                    wc = WordCloud(
                        width=400, 
                        height=300, 
                        background_color='white',
                        max_words=50
                    ).generate(all_keywords)
                    
                    fig, ax = plt.subplots(figsize=(6, 4))
                    ax.imshow(wc, interpolation='bilinear')
                    ax.axis("off")
                    st.pyplot(fig)
                except Exception as e:
                    st.warning(f"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            else:
                st.info("ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("í†µê³„ë¥¼ í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

with tab3:
    st.subheader("ğŸ“ ë¶ë§ˆí¬ ë° PDF ì €ì¥")
    
    bookmarked_links = st.session_state.get("bookmarks", [])
    if bookmarked_links and not news_df.empty:
        bm_df = news_df[news_df["ë§í¬"].isin(bookmarked_links)]
        
        if not bm_df.empty:
            st.write(f"ğŸ“Œ ë¶ë§ˆí¬ëœ ë‰´ìŠ¤: {len(bm_df)}ê°œ")
            
            for _, row in bm_df.iterrows():
                senti_emo = SENTI_EMOJI.get(row['ê°ì„±'], 'ğŸŸ¡')
                tone_emo = TONE_EMOJI.get(row['ì½˜í…ì¸ í†¤'], 'â„¹ï¸')
                st.markdown(f"- {senti_emo}{tone_emo} **{row['ì œëª©']}**")
                st.markdown(f"  ğŸ”— {row['ë§í¬']}")
                st.markdown("---")
            
            # CSV ë‹¤ìš´ë¡œë“œë¡œ ë³€ê²½ (í•œê¸€ ì§€ì›)
            if st.button("â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ"):
                try:
                    # CSV í˜•íƒœë¡œ ë°ì´í„° ì¤€ë¹„
                    csv_data = bm_df[['í‚¤ì›Œë“œ', 'ì œëª©', 'ìš”ì•½', 'ê°ì„±', 'ì½˜í…ì¸ í†¤', 'í‚¤ì›Œë“œì¶”ì¶œ', 'íƒœê·¸', 'í•œì¤„í‰', 'ë§í¬']].copy()
                    csv_string = csv_data.to_csv(index=False, encoding='utf-8-sig')
                    
                    st.download_button(
                        "ğŸ“„ CSV íŒŒì¼ ì €ì¥",
                        data=csv_string.encode('utf-8-sig'),
                        file_name=f"bookmarked_news_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                    st.success("CSV íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                except Exception as e:
                    st.error(f"CSV ìƒì„± ì‹¤íŒ¨: {e}")
            
            # í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì¶”ê°€
            if st.button("ğŸ“ í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"):
                try:
                    text_content = "=== ë¶ë§ˆí¬ëœ ë‰´ìŠ¤ ìš”ì•½ ===\n\n"
                    for i, row in bm_df.iterrows():
                        text_content += f"""
ğŸ“° ì œëª©: {row['ì œëª©']}
ğŸ”— ë§í¬: {row['ë§í¬']}
ğŸ“… ë‚ ì§œ: {row['ë‚ ì§œ']}
ğŸ§¾ ìš”ì•½: {row['ìš”ì•½']}
ğŸ’­ í•œì¤„í‰: {row['í•œì¤„í‰']}
ğŸ˜¶ ê°ì„±: {row['ê°ì„±']} | ğŸ§ í†¤: {row['ì½˜í…ì¸ í†¤']}
ğŸ·ï¸ í‚¤ì›Œë“œ: {row['í‚¤ì›Œë“œì¶”ì¶œ']}
ğŸ·ï¸ íƒœê·¸: {row['íƒœê·¸']}

{'='*60}

"""
                    
                    st.download_button(
                        "ğŸ“ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥",
                        data=text_content.encode('utf-8'),
                        file_name=f"bookmarked_news_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                    st.success("í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                except Exception as e:
                    st.error(f"í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        else:
            st.info("ë¶ë§ˆí¬ëœ ë‰´ìŠ¤ê°€ í˜„ì¬ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("â­ ë¶ë§ˆí¬ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")